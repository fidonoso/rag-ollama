
# üßÆüó®Ô∏è  ChromaDB | Ollama | Docker
### Usar modelos ia locales con ollama para preguntar a tus documentos pdf¬¥s

üöÄ [Youtube](https://youtu.be/xTZwhgdj6z4)

¬øQu√© es una base de datos vectorial? ChromaDB es una base de datos vectorial optimizada para almacenar, indexar y consultar datos en formato vectorial. Las bases de datos vectoriales est√°n dise√±adas para manejar datos de alta dimensionalidad, como los vectores generados por modelos de machine learning y procesamiento del lenguaje natural (NLP).

¬øQu√© es ollama? Ollama es una herramienta que permite ejecutar modelos de lenguaje de inteligencia artificial (IA) localmente en tu computadora, sin necesidad de conectarse a la nube. Est√° dise√±ada para facilitar el uso de grandes modelos de IA, como GPT, directamente en dispositivos personales, manteniendo la privacidad y reduciendo la latencia. Ollama simplifica la instalaci√≥n y el uso de estos modelos a trav√©s de una interfaz de l√≠nea de comandos. Es √∫til para desarrolladores y usuarios que desean experimentar con modelos de IA avanzados sin depender de servicios en la nube.

¬øQu√© es docker y docker-compose? Docker es una plataforma de contenedorizaci√≥n que permite empaquetar aplicaciones y sus dependencias en contenedores ligeros y port√°tiles, asegurando que funcionen de manera consistente en cualquier entorno. Docker Compose es una herramienta que facilita la definici√≥n y gesti√≥n de aplicaciones multicontenedor, permitiendo describir la configuraci√≥n de todos los servicios, redes y vol√∫menes necesarios en un archivo YAML (docker-compose.yml) y luego desplegarlos juntos con un solo comando.

Para ejecutar esta aplicaci√≥n es necesario contar con:
* [Docker](https://docs.docker.com/engine/install/)
* [Ollama](https://ollama.com/) 
* [Streamlit](https://streamlit.io/)


## ¬øC√≥mo funciona?
1. Divide documento en pedacitos (o chunks)
2. Crea los embeddings de los pedacitos de texto
3. Guarda los pedacitos y los embeddings en ChromaDB
4. Busca los pedacitos m√°s similares a la pregunta del usuario gracias a los embeddings.
5. Pasa los pedacitos m√°s similares junto a la pregunta al servicio de ollama usando el modelo llama3.1 que generar√° la respuesta


## Instalaci√≥n

1. Clone o descargue el repositorio en su m√°quina local.
2. Instale las bibliotecas requeridas ejecutando el siguiente comando en su terminal (recomiendo un entorno virtual como venv):
    ```bash
    pip install -r requirements.txt
    ```
3. Desplegar ChromaDB usando `docker-compose up -d` en una terminal posicionado en la raiz del proyecto. Esto levantar√° la base de datos vectorial accesible para la aplicacion desde `http://localhost:8000`. Puedes verificar la api del servicio en `http://localhost:8000/docs` (openapi)
4. Ejecute la aplicaci√≥n con el siguiente comando:
    ```bash
    streamlit run app.py
    ```
1. Suba un documento a la aplicaci√≥n.
2. Escriba su pregunta y disfrute de la magia.

## Agradecimientos
Me bas√© en proyectos de estos dos grandes maestros para crear este √∫til Frankenstein

- [NechuBM](https://www.youtube.com/@NechuBM)
- [CodingMindsetIO](https://www.youtube.com/@CodingMindsetIO)